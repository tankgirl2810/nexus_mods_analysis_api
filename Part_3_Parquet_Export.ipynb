{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Parquet Export\n",
    "\n",
    "This notebook exports SQL Server data to Parquet files for data sharing and archival. This isn't required unless you are sharing the data and don't want to share where you stored it\n",
    "\n",
    "## Overview\n",
    "- Export all SQL tables and views to Parquet format\n",
    "- Handle large datasets by splitting into chunks\n",
    "- Create ZIP archive of selected data for sharing\n",
    "\n",
    "## Output\n",
    "- Parquet files for each table/view\n",
    "- ZIP archive with selected views and tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://username:password@server.database.windows.net/NexusModsDB?driver=ODBC+Driver+17+for+SQL+Server&Connect Timeout=60\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OUTPUT_DIR = r\"C:\\Mod_data\"  \n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Objects to include in ZIP file for sharing\n",
    "ZIP_OBJECTS = {'Authors_di', 'Mods_di', 'Games'}\n",
    "\n",
    "# Maximum rows per parquet file (for splitting large tables)\n",
    "ROW_LIMIT = 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List Available Tables and Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of tables and views\n",
    "inspector = inspect(engine)\n",
    "tables = inspector.get_table_names()\n",
    "views = inspector.get_view_names()\n",
    "\n",
    "print(f\"Tables ({len(tables)}):\")\n",
    "for t in tables:\n",
    "    print(f\"  - {t}\")\n",
    "\n",
    "print(f\"\\nViews ({len(views)}):\")\n",
    "for v in views:\n",
    "    print(f\"  - {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_and_split(df, name, output_dir, row_limit=ROW_LIMIT):\n",
    "    '''\n",
    "    Export DataFrame to Parquet, splitting into multiple files if needed.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to export\n",
    "        name: Base name for output files\n",
    "        output_dir: Directory to save files\n",
    "        row_limit: Maximum rows per file\n",
    "    \n",
    "    Returns:\n",
    "        list: List of created filenames\n",
    "    '''\n",
    "    if len(df) == 0:\n",
    "        return []\n",
    "    \n",
    "    chunks = [df[i:i + row_limit] for i in range(0, len(df), row_limit)]\n",
    "    filenames = []\n",
    "    \n",
    "    for idx, chunk in enumerate(chunks, start=1):\n",
    "        suffix = f\"_{idx}\" if len(chunks) > 1 else \"\"\n",
    "        filename = f\"{name}{suffix}.parquet\"\n",
    "        path = os.path.join(output_dir, filename)\n",
    "        chunk.to_parquet(path, index=False)\n",
    "        filenames.append(filename)\n",
    "    \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_all_objects(tables, views, output_dir):\n",
    "    '''\n",
    "    Export all tables and views to Parquet files.\n",
    "    \n",
    "    Args:\n",
    "        tables: List of table names\n",
    "        views: List of view names\n",
    "        output_dir: Output directory\n",
    "    \n",
    "    Returns:\n",
    "        list: Export timing results\n",
    "    '''\n",
    "    all_objects = tables + views\n",
    "    print(f\"Found {len(tables)} tables and {len(views)} views. Starting export...\")\n",
    "    \n",
    "    export_times = []\n",
    "    \n",
    "    for name in tqdm(all_objects, desc=\"Exporting SQL objects\", unit=\"object\"):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Read data from SQL\n",
    "            df = pd.read_sql_query(f\"SELECT * FROM [{name}]\", engine)\n",
    "            \n",
    "            # Export to parquet\n",
    "            files = export_and_split(df, name, output_dir)\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            export_times.append((name, len(df), len(files), round(duration, 2)))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting '{name}': {e}\")\n",
    "    \n",
    "    return export_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zip_archive(output_dir, zip_objects, zip_filename):\n",
    "    '''\n",
    "    Create ZIP archive with selected objects.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory containing parquet files\n",
    "        zip_objects: Set of object names to include\n",
    "        zip_filename: Name for the ZIP file\n",
    "    '''\n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for obj in zip_objects:\n",
    "            part_idx = 1\n",
    "            while True:\n",
    "                # Handle split files\n",
    "                if part_idx == 1:\n",
    "                    filename = f\"{obj}.parquet\"\n",
    "                else:\n",
    "                    filename = f\"{obj}_{part_idx}.parquet\"\n",
    "                \n",
    "                file_path = os.path.join(output_dir, filename)\n",
    "                \n",
    "                if os.path.exists(file_path):\n",
    "                    zipf.write(file_path, arcname=filename)\n",
    "                    part_idx += 1\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "    print(f\"ZIP archive created: {zip_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all objects\n",
    "export_times = export_all_objects(tables, views, OUTPUT_DIR)\n",
    "for name, rows, parts, duration in export_times:\n",
    "    print(f\"{name:<30} | {rows:>10,} | {parts:>5} | {duration:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_filename = \"NexusModsDB_selected_views_and_table.zip\"\n",
    "create_zip_archive(OUTPUT_DIR, ZIP_OBJECTS, zip_filename)\n",
    "\n",
    "print(f\"\\nExport complete!\")\n",
    "print(f\"All Parquet files saved in: {OUTPUT_DIR}\")\n",
    "print(f\"Selected objects zipped to: {zip_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display sample from exported data\n",
    "sample_file = os.path.join(OUTPUT_DIR, \"Authors_di.parquet\")\n",
    "\n",
    "if os.path.exists(sample_file):\n",
    "    df_sample = pd.read_parquet(sample_file)\n",
    "    print(f\"Sample from Authors_di.parquet ({len(df_sample)} rows):\")\n",
    "    display(df_sample.head())\n",
    "else:\n",
    "    print(f\"Sample file not found: {sample_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
